{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7TakU/zMoWtgNmkdirqlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbehargithub/MuskTweets-Impact-on-TeslaStock/blob/main/tweets_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "RAxoVbZPKEOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "I3lXsu_50dr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import time\n",
        "\n",
        "# Load pre-trained model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Load your tweets data\n",
        "tweets_df = pd.read_csv('/content/merged_df.csv')  # Adjust the path to your CSV file\n",
        "\n",
        "# Select the first 10000 tweets for testing\n",
        "# tweets_df = tweets_df.head(10000)\n",
        "\n",
        "# Retain only relevant columns\n",
        "tweets_df = tweets_df[['index', 'text']]\n",
        "\n",
        "# Define keyword categories\n",
        "primary_keywords = ['Tesla', 'TSLA', 'Elon Musk', 'Model S', 'Model 3', 'Model X',\n",
        "                    'Model Y', 'Cybertruck', 'Roadster', 'Semi', 'Autopilot',\n",
        "                    'Full Self-Driving', 'Gigafactory', 'Solar Roof', 'Powerwall', 'Starlink']\n",
        "\n",
        "secondary_keywords = ['@Tesla', 'Electric Vehicle', 'Battery', 'Lithium-ion', 'Renewable Energy',\n",
        "                      'Autonomous Driving', 'Clean Energy', 'Sustainable Energy',\n",
        "                      'Energy Storage', 'Solar Energy', 'Charging Infrastructure',\n",
        "                      'Supercharger', 'AI', 'Machine Learning', 'Autonomous Vehicles',\n",
        "                      'Green Technology', 'Smart Grid']\n",
        "\n",
        "financial_keywords = ['Stock', 'NASDAQ', 'Earnings', 'Share', 'Dividend', 'Market Cap',\n",
        "                      'Valuation', 'Quarterly Report', 'Profit', 'Revenue', 'EPS',\n",
        "                      'Buyback', 'Stock Split', 'Shareholders', 'Financial Results',\n",
        "                      'Forecast', 'Guidance', 'Analyst Rating', 'Price Target',\n",
        "                      'Upgrade', 'Downgrade', 'SEC Filing', 'IPO', 'Mergers and Acquisitions',\n",
        "                      'Investment', 'Contract']\n",
        "\n",
        "# Keyword matching scores\n",
        "tweets_df['primary_keyword_score'] = tweets_df['text'].apply(lambda x: sum(1 for kw in primary_keywords if kw.lower() in x.lower()))\n",
        "tweets_df['secondary_keyword_score'] = tweets_df['text'].apply(lambda x: sum(1 for kw in secondary_keywords if kw.lower() in x.lower()))\n",
        "\n",
        "# Update financial_keyword_score to 0 if both primary and secondary scores are 0\n",
        "tweets_df['financial_keyword_score'] = tweets_df.apply(\n",
        "    lambda row: sum(1 for kw in financial_keywords if kw.lower() in row['text'].lower()) if row['primary_keyword_score'] > 0 or row['secondary_keyword_score'] > 0 else 0,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Total keyword score with different weights for each category\n",
        "tweets_df['keyword_score'] = (tweets_df['primary_keyword_score'] * 5) + (tweets_df['secondary_keyword_score'] * 2) + tweets_df['financial_keyword_score']\n",
        "\n",
        "# Define a reference text for Tesla-related topics\n",
        "reference_text = \"\"\"\n",
        "Tesla Inc. is a company that designs, manufactures, and sells electric vehicles and energy storage products.\n",
        "Tesla's stock price is influenced by various factors, including company performance, innovations in electric vehicle technology,\n",
        "statements and actions by CEO Elon Musk, market trends, and economic conditions.\n",
        "\"\"\"\n",
        "\n",
        "# Compute reference embedding\n",
        "reference_embedding = model.encode(reference_text, convert_to_tensor=True)\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(tweet):\n",
        "    blob = TextBlob(tweet)\n",
        "    sentiment_polarity = blob.sentiment.polarity\n",
        "    sentiment_score = (sentiment_polarity + 1) * 5  # Convert polarity (-1 to 1) to score (1 to 10)\n",
        "    return sentiment_score\n",
        "\n",
        "# Function to analyze relevance\n",
        "def compute_similarity(tweet):\n",
        "    tweet_embedding = model.encode(tweet, convert_to_tensor=True)\n",
        "    similarity = util.cos_sim(tweet_embedding, reference_embedding).item()\n",
        "    return similarity\n",
        "\n",
        "# Function to normalize similarity (Z-score normalization)\n",
        "def normalize_similarity(similarity, mean_similarity, std_similarity):\n",
        "    z_score = (similarity - mean_similarity) / std_similarity\n",
        "    return z_score\n",
        "\n",
        "# Scale absolute z-scores to range [1, 10]\n",
        "def scale_to_range_1_10(z_score, min_z, max_z):\n",
        "    scaled_score = ((abs(z_score) - min_z) / (max_z - min_z)) * 9 + 1\n",
        "    return scaled_score\n",
        "\"\"\"\n",
        "# Function to analyze volume with weighted sum\n",
        "def analyze_volume(likes, retweets, replies):\n",
        "    weight_likes = 0.2\n",
        "    weight_retweets = 0.4\n",
        "    weight_replies = 0.4\n",
        "\n",
        "    volume_score = weight_likes * likes + weight_retweets * retweets + weight_replies * replies\n",
        "    volume_score = np.log1p(volume_score)\n",
        "    max_volume = np.log1p(tweets_df[['likes_count', 'retweets_count', 'replies_count']].max().sum())\n",
        "    volume_score = (volume_score / max_volume) * 10\n",
        "    return volume_score\n",
        "\"\"\"\n",
        "# Start analysis\n",
        "start_time = time.time()\n",
        "\n",
        "# Analyze sentiment\n",
        "tweets_df['sentiment_score'] = tweets_df['text'].apply(analyze_sentiment)\n",
        "sentiment_end_time = time.time()\n",
        "\n",
        "# Analyze volume\n",
        "\"\"\"\n",
        "tweets_df['volume_score'] = tweets_df.apply(lambda row: analyze_volume(row['likes_count'], row['retweets_count'], row['replies_count']), axis=1)\n",
        "volume_end_time = time.time()\n",
        "\"\"\"\n",
        "# Analyze relevance\n",
        "tweets_df['similarity'] = tweets_df['text'].apply(compute_similarity)\n",
        "tweets_df['abs_similarity'] = tweets_df['similarity'].apply(abs)\n",
        "mean_similarity = tweets_df['abs_similarity'].mean()\n",
        "std_similarity = tweets_df['abs_similarity'].std()\n",
        "\n",
        "tweets_df['z_score'] = tweets_df['abs_similarity'].apply(lambda x: normalize_similarity(x, mean_similarity, std_similarity))\n",
        "min_z = tweets_df['z_score'].abs().min()\n",
        "max_z = tweets_df['z_score'].abs().max()\n",
        "tweets_df['relevance_score'] = tweets_df['z_score'].apply(lambda x: scale_to_range_1_10(x, min_z, max_z))\n",
        "relevance_end_time = time.time()\n",
        "\n",
        "# Calculate adjusted weights for similarity based on the number of keywords\n",
        "def adjusted_similarity_weight(keyword_score):\n",
        "    return min(0.1 + (keyword_score * 0.1), 1.0)\n",
        "\n",
        "tweets_df['similarity_weight'] = tweets_df['keyword_score'].apply(adjusted_similarity_weight)\n",
        "tweets_df['keyword_weight'] = 1 - tweets_df['similarity_weight']\n",
        "\n",
        "# Calculate the final relevance using the adjusted weights\n",
        "tweets_df['final_relevance'] = (tweets_df['keyword_weight'] * tweets_df['keyword_score']) + (tweets_df['similarity_weight'] * tweets_df['relevance_score'])\n",
        "\n",
        "# Normalize final score to the range [1, 10]\n",
        "final_scaler = MinMaxScaler(feature_range=(1, 10))\n",
        "tweets_df['final_relevance'] = final_scaler.fit_transform(tweets_df[['final_relevance']])\n",
        "\n",
        "\"\"\"\n",
        "# Calculate the final rating using sentiment, relevance, and volume\n",
        "tweets_df['final_rating'] = (tweets_df['sentiment_score'].astype(float) * 0.4 +\n",
        "                             tweets_df['final_relevance'].astype(float) * 0.4 +\n",
        "                             tweets_df['volume_score'] * 0.2)\n",
        "\"\"\"\n",
        "# Format scores to two decimal places\n",
        "tweets_df['sentiment_score'] = tweets_df['sentiment_score'].apply(lambda x: f\"{x:.2f}\")\n",
        "tweets_df['final_relevance'] = tweets_df['final_relevance'].apply(lambda x: f\"{x:.2f}\")\n",
        "# tweets_df['volume_score'] = tweets_df['volume_score'].apply(lambda x: f\"{x:.2f}\")\n",
        "# tweets_df['final_rating'] = tweets_df['final_rating'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Drop intermediate columns\n",
        "\"\"\"\n",
        "tweets_df = tweets_df.drop(columns=['primary_keyword_score', 'secondary_keyword_score', 'financial_keyword_score',\n",
        "                                    'similarity', 'abs_similarity', 'z_score', 'similarity_weight', 'keyword_weight',\n",
        "                                    'relevance_score'])\n",
        "\"\"\"\n",
        "\n",
        "# Reorder columns to place scores after the tweet column\n",
        "cols = list(tweets_df.columns)\n",
        "cols.insert(cols.index('text') + 1, cols.pop(cols.index('sentiment_score')))\n",
        "cols.insert(cols.index('text') + 2, cols.pop(cols.index('final_relevance')))\n",
        "#cols.insert(cols.index('text') + 3, cols.pop(cols.index('volume_score')))\n",
        "# cols.insert(cols.index('text') + 4, cols.pop(cols.index('final_rating')))\n",
        "tweets_df = tweets_df[cols]\n",
        "\n",
        "# Print timing results\n",
        "print(f\"Sentiment Analysis Time: {sentiment_end_time - start_time:.2f} seconds\")\n",
        "#print(f\"Volume Analysis Time: {volume_end_time - sentiment_end_time:.2f} seconds\")\n",
        "#print(f\"Relevance Analysis Time: {relevance_end_time - volume_end_time:.2f} seconds\")\n",
        "\n",
        "# Save or display the results\n",
        "tweets_df.to_csv('tweets_with_analysis_scores.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJJYAiyWrFIY",
        "outputId": "4a14d19b-4ecc-4dfc-e5bb-72bbc3b020c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis Time: 1.22 seconds\n"
          ]
        }
      ]
    }
  ]
}